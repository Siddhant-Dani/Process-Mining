{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52492ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pm4py\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ce0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local directory with logs (can be changed as per need)\n",
    "train_directory = \"D:\\Siddhant\\Masters Project\\Dataset\\Process Discovery Contest 2023_1_all\\Training Logs\"\n",
    "\n",
    "#extracting concept names\n",
    "def extract_concept_names(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    concept_names = []\n",
    "    for trace in root.iter('trace'):\n",
    "        for event in trace.iter('event'):\n",
    "            for string in event.iter('string'):\n",
    "                if string.attrib.get('key') == 'concept:name':\n",
    "                    concept_names.append(string.attrib['value'])\n",
    "        #end of case token\n",
    "        concept_names.append('<END>')\n",
    "    \n",
    "    return concept_names\n",
    "\n",
    "# Function to read and combine logs from all files in the directory\n",
    "def read_and_combine_logs(directory):\n",
    "    combined_activities = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.xes'):\n",
    "            log_path = os.path.join(directory, filename)\n",
    "            concept_names = extract_concept_names(log_path)\n",
    "            combined_activities.extend(concept_names)\n",
    "    return combined_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2426b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of activities extracted: 6914778\n"
     ]
    }
   ],
   "source": [
    "combined_activities = read_and_combine_logs(train_directory)\n",
    "print(f\"Number of activities extracted: {len(combined_activities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd29806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert activities to categorical codes\n",
    "activity_codes = pd.Series(combined_activities).astype('category').cat.codes\n",
    "unique_activities = pd.Series(combined_activities).astype('category').cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6f6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "next_activities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a7f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 25\n",
    "num_classes = len(unique_activities)\n",
    "batch_size = 16\n",
    "\n",
    "def sequence_generator(activity_codes, batch_size, max_sequence_length, num_classes):\n",
    "    while True:\n",
    "        indices = list(range(1, len(activity_codes)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        sequences = []\n",
    "        next_activities = []\n",
    "        \n",
    "        for i in indices:\n",
    "            if activity_codes[i] == '<END>':\n",
    "                continue  # Skip end-of-case tokens for next activity prediction\n",
    "\n",
    "            seq = activity_codes[:i].tolist()\n",
    "            next_act = activity_codes[i]\n",
    "\n",
    "            # Stop the sequence at the end-of-case token\n",
    "            if '<END>' in seq:\n",
    "                end_index = seq.index('<END>')\n",
    "                seq = seq[:end_index + 1]\n",
    "\n",
    "            sequences.append(seq)\n",
    "            next_activities.append(next_act)\n",
    "            \n",
    "            if len(sequences) == batch_size:\n",
    "                X = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre')\n",
    "                y = to_categorical(next_activities, num_classes=num_classes)\n",
    "                yield X, y\n",
    "                sequences = []\n",
    "                next_activities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e0e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_classes, output_dim=64, batch_input_shape=(batch_size, max_sequence_length)))\n",
    "model.add(LSTM(50, stateful=True, return_sequences=False))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5110f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Siddhant\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Siddhant\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_stateful_model(model, generator, steps_per_epoch, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}/{epochs}')\n",
    "        model.reset_states()  # Reset states at the beginning of each epoch\n",
    "        for step in range(steps_per_epoch):\n",
    "            X, y = next(generator)\n",
    "            model.train_on_batch(X, y)\n",
    "\n",
    "#steps per epoch\n",
    "steps_per_epoch = len(activity_codes) // batch_size\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "train_stateful_model(model, sequence_generator(activity_codes, batch_size, max_sequence_length, num_classes), steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff93a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.reset_states()\n",
    "for step in range(steps_per_epoch):\n",
    "    X, y = next(sequence_generator(activity_codes, batch_size, max_sequence_length, num_classes))\n",
    "    loss, accuracy = model.test_on_batch(X, y)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
